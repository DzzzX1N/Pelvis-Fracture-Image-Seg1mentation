{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net 3D CT Segmentation\n",
    "\n",
    "This notebook implements a 3D U-Net model for segmenting pelvis from CT scans.\n",
    "\n",
    "## Setup and Imports\n",
    "\n",
    "First, let's check our environment and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4070\n",
      "SimpleITK version: 2.4.0\n",
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "!pip install SimpleITK\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "\n",
    "\n",
    "# Print versions for reproducibility\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"SimpleITK version: {sitk.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration\n",
    "Let's examine our dataset structure and visualize some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 image files in ../data\\PENGWIN_CT_train_images\n",
      "Found 100 label files in ../data\\PENGWIN_CT_train_labels\n",
      "\n",
      "First 5 image files:\n",
      "- 001.mha\n",
      "- 002.mha\n",
      "- 003.mha\n",
      "- 004.mha\n",
      "- 005.mha\n",
      "\n",
      "Original image dimensions: (401, 512, 512)\n",
      "Image spacing: (0.78125, 0.78125, 0.800000011920929)\n",
      "Value range: [-1023.00, 2775.00] HU\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "drive.mount('/content/drive')\n",
    "data_dir = '/content/drive/MyDrive/data'\n",
    "BASE_DIR = '/content/drive/MyDrive/ct_segmentation'  # Create a dedicated project folder\n",
    "\n",
    "# Create organized subdirectories\n",
    "PATHS = {\n",
    "    'data': f'{BASE_DIR}/data',\n",
    "    'models': f'{BASE_DIR}/models',\n",
    "    'checkpoints': f'{BASE_DIR}/checkpoints',\n",
    "    'results': f'{BASE_DIR}/results',\n",
    "    'logs': f'{BASE_DIR}/logs'\n",
    "}\n",
    "\n",
    "# Create all directories\n",
    "for path in PATHS.values():\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Update data paths\n",
    "images_path = os.path.join(PATHS['data'], 'PENGWIN_CT_train_images')\n",
    "labels_path = os.path.join(PATHS['data'], 'PENGWIN_CT_train_labels')\n",
    "\n",
    "# Update model save paths\n",
    "MODEL_SAVE_PATH = os.path.join(PATHS['models'], 'best_unet_model.pth')\n",
    "CHECKPOINT_DIR = PATHS['checkpoints']\n",
    "\n",
    "# List and count files\n",
    "image_files = sorted([f for f in os.listdir(images_path) if f.endswith('.mha')])\n",
    "label_files = sorted([f for f in os.listdir(labels_path) if f.endswith('.mha')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTScanDataset(Dataset):\n",
    "    def __init__(self, images_path, labels_path, patch_size=(128, 128, 128), stride=(64, 64, 64)):\n",
    "        self.image_paths = sorted([os.path.join(images_path, fname) \n",
    "                                for fname in os.listdir(images_path) \n",
    "                                if fname.endswith('.mha')])\n",
    "        self.label_paths = sorted([os.path.join(labels_path, fname) \n",
    "                                for fname in os.listdir(labels_path) \n",
    "                                if fname.endswith('.mha')])\n",
    "        \n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        \n",
    "        assert len(self.image_paths) == len(self.label_paths)\n",
    "\n",
    "    def extract_patches(self, image, label):\n",
    "        \"\"\"Extract patches from image and label\"\"\"\n",
    "        patches_img = []\n",
    "        patches_label = []\n",
    "        \n",
    "        D, H, W = image.shape\n",
    "        \n",
    "        # Calculate steps for each dimension\n",
    "        d_steps = range(0, D - self.patch_size[0] + 1, self.stride[0])\n",
    "        h_steps = range(0, H - self.patch_size[1] + 1, self.stride[1])\n",
    "        w_steps = range(0, W - self.patch_size[2] + 1, self.stride[2])\n",
    "        \n",
    "        # If image is smaller than patch size, pad it\n",
    "        if D < self.patch_size[0]:\n",
    "            d_steps = [0]\n",
    "        if H < self.patch_size[1]:\n",
    "            h_steps = [0]\n",
    "        if W < self.patch_size[2]:\n",
    "            w_steps = [0]\n",
    "            \n",
    "        for d in d_steps:\n",
    "            for h in h_steps:\n",
    "                for w in w_steps:\n",
    "                    # Extract patches\n",
    "                    d_end = min(d + self.patch_size[0], D)\n",
    "                    h_end = min(h + self.patch_size[1], H)\n",
    "                    w_end = min(w + self.patch_size[2], W)\n",
    "                    \n",
    "                    patch_img = image[d:d_end, h:h_end, w:w_end]\n",
    "                    patch_label = label[d:d_end, h:h_end, w:w_end]\n",
    "                    \n",
    "                    # Pad if necessary\n",
    "                    if patch_img.shape != self.patch_size:\n",
    "                        pad_d = self.patch_size[0] - patch_img.shape[0]\n",
    "                        pad_h = self.patch_size[1] - patch_img.shape[1]\n",
    "                        pad_w = self.patch_size[2] - patch_img.shape[2]\n",
    "                        \n",
    "                        patch_img = np.pad(patch_img, \n",
    "                                         ((0, pad_d), (0, pad_h), (0, pad_w)), \n",
    "                                         mode='constant')\n",
    "                        patch_label = np.pad(patch_label, \n",
    "                                           ((0, pad_d), (0, pad_h), (0, pad_w)), \n",
    "                                           mode='constant')\n",
    "                    \n",
    "                    patches_img.append(patch_img)\n",
    "                    patches_label.append(patch_label)\n",
    "        \n",
    "        return np.array(patches_img), np.array(patches_label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and label\n",
    "        image = sitk.GetArrayFromImage(sitk.ReadImage(self.image_paths[idx])).astype(np.float32)\n",
    "        label = sitk.GetArrayFromImage(sitk.ReadImage(self.label_paths[idx])).astype(np.float32)\n",
    "        \n",
    "        # Preprocessing\n",
    "        image = np.clip(image, -1000, 1000)\n",
    "        image = (image + 1000) / 2000\n",
    "        label = (label > 0).astype(np.float32)\n",
    "        \n",
    "        # Extract patches\n",
    "        patches_img, patches_label = self.extract_patches(image, label)\n",
    "        \n",
    "        # Randomly select one patch during training\n",
    "        patch_idx = np.random.randint(len(patches_img))\n",
    "        \n",
    "        # Add channel dimension\n",
    "        image_patch = np.expand_dims(patches_img[patch_idx], axis=0)\n",
    "        label_patch = np.expand_dims(patches_label[patch_idx], axis=0)\n",
    "        \n",
    "        return torch.tensor(image_patch), torch.tensor(label_patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_image_path, val_label_path, patch_size=(128, 128, 128)):\n",
    "    \"\"\"\n",
    "    Validate model performance on a single validation image\n",
    "    Returns Dice score\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Load validation image and label\n",
    "    val_image = sitk.GetArrayFromImage(sitk.ReadImage(val_image_path)).astype(np.float32)\n",
    "    val_label = sitk.GetArrayFromImage(sitk.ReadImage(val_label_path)).astype(np.float32)\n",
    "    \n",
    "    # Preprocess\n",
    "    val_image = np.clip(val_image, -1000, 1000)\n",
    "    val_image = (val_image + 1000) / 2000\n",
    "    val_label = (val_label > 0).astype(np.float32)\n",
    "    \n",
    "    # Predict using sliding window\n",
    "    prediction = predict_volume(model, val_image, patch_size=patch_size)\n",
    "    \n",
    "    # Apply sigmoid and threshold\n",
    "    prediction = (prediction > 0.5).astype(np.float32)\n",
    "    \n",
    "    # Calculate Dice score\n",
    "    intersection = np.sum(prediction * val_label)\n",
    "    dice_score = (2. * intersection) / (np.sum(prediction) + np.sum(val_label) + 1e-7)\n",
    "    \n",
    "    return dice_score\n",
    "\n",
    "def predict_volume(model, image, patch_size=(128, 128, 128), stride=(32, 32, 32)):  # 减小stride\n",
    "    \"\"\"Predict segmentation using sliding window approach with Gaussian weighting\"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    D, H, W = image.shape\n",
    "    output = np.zeros_like(image, dtype=np.float32)\n",
    "    weight = np.zeros_like(image, dtype=np.float32)\n",
    "    \n",
    "    # 创建3D高斯权重核\n",
    "    def gaussian_kernel(size):\n",
    "        sigma = size/8\n",
    "        x = np.linspace(-size/2, size/2, size)\n",
    "        x, y, z = np.meshgrid(x, x, x)\n",
    "        kernel = np.exp(-(x**2 + y**2 + z**2)/(2*sigma**2))\n",
    "        return kernel/kernel.max()\n",
    "    \n",
    "    weight_kernel = gaussian_kernel(patch_size[0])\n",
    "    \n",
    "    # Calculate steps\n",
    "    d_steps = range(0, D - patch_size[0] + 1, stride[0])\n",
    "    h_steps = range(0, H - patch_size[1] + 1, stride[1])\n",
    "    w_steps = range(0, W - patch_size[2] + 1, stride[2])\n",
    "    \n",
    "    # Handle edge cases\n",
    "    if D < patch_size[0]:\n",
    "        d_steps = [0]\n",
    "    if H < patch_size[1]:\n",
    "        h_steps = [0]\n",
    "    if W < patch_size[2]:\n",
    "        w_steps = [0]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in d_steps:\n",
    "            for h in h_steps:\n",
    "                for w in w_steps:\n",
    "                    # Extract patch\n",
    "                    d_end = min(d + patch_size[0], D)\n",
    "                    h_end = min(h + patch_size[1], H)\n",
    "                    w_end = min(w + patch_size[2], W)\n",
    "                    \n",
    "                    patch = image[d:d_end, h:h_end, w:w_end]\n",
    "                    \n",
    "                    # Pad if necessary\n",
    "                    if patch.shape != patch_size:\n",
    "                        pad_d = patch_size[0] - patch.shape[0]\n",
    "                        pad_h = patch_size[1] - patch.shape[1]\n",
    "                        pad_w = patch_size[2] - patch.shape[2]\n",
    "                        \n",
    "                        patch = np.pad(patch, \n",
    "                                     ((0, pad_d), (0, pad_h), (0, pad_w)), \n",
    "                                     mode='constant')\n",
    "                    \n",
    "                    # Predict\n",
    "                    patch = torch.tensor(patch).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "                    pred = torch.sigmoid(model(patch)).cpu().numpy()[0, 0]\n",
    "                    \n",
    "                    # Unpad if necessary\n",
    "                    if pad_d > 0 or pad_h > 0 or pad_w > 0:\n",
    "                        pred = pred[:d_end-d, :h_end-h, :w_end-w]\n",
    "                        kernel = weight_kernel[:d_end-d, :h_end-h, :w_end-w]\n",
    "                    else:\n",
    "                        kernel = weight_kernel\n",
    "                    \n",
    "                    # Add to output with Gaussian weight\n",
    "                    output[d:d_end, h:h_end, w:w_end] += pred * kernel\n",
    "                    weight[d:d_end, h:h_end, w:w_end] += kernel\n",
    "    \n",
    "    # Average overlapping predictions\n",
    "    output = np.divide(output, weight, where=weight!=0)\n",
    "    return output\n",
    "\n",
    "# 添加后处理函数\n",
    "def post_process_prediction(pred, min_size=100):\n",
    "    \"\"\"\n",
    "    Post-process the prediction to remove small regions and smooth boundaries\n",
    "    \"\"\"\n",
    "    from scipy import ndimage\n",
    "    \n",
    "    # Threshold\n",
    "    binary = (pred > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Remove small regions\n",
    "    labeled, num_features = ndimage.label(binary)\n",
    "    for i in range(1, num_features + 1):\n",
    "        mask = (labeled == i)\n",
    "        if np.sum(mask) < min_size:\n",
    "            binary[mask] = 0\n",
    "            \n",
    "    # Morphological operations\n",
    "    binary = ndimage.binary_closing(binary, structure=np.ones((3,3,3)))\n",
    "    binary = ndimage.binary_opening(binary, structure=np.ones((3,3,3)))\n",
    "    \n",
    "    return binary\n",
    "\n",
    "# 在validate函数中使用新的预测和后处理\n",
    "def validate(model, val_image_path, val_label_path, patch_size=(128, 128, 128)):\n",
    "    \"\"\"\n",
    "    Validate model performance on a single validation image\n",
    "    Returns Dice score\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    # Load validation image and label\n",
    "    val_image = sitk.GetArrayFromImage(sitk.ReadImage(val_image_path)).astype(np.float32)\n",
    "    val_label = sitk.GetArrayFromImage(sitk.ReadImage(val_label_path)).astype(np.float32)\n",
    "    \n",
    "    # Preprocess\n",
    "    val_image = np.clip(val_image, -1000, 1000)\n",
    "    val_image = (val_image + 1000) / 2000\n",
    "    val_label = (val_label > 0).astype(np.float32)\n",
    "    \n",
    "    # Predict using sliding window and post-process\n",
    "    prediction = predict_volume(model, val_image, patch_size=patch_size)\n",
    "    prediction = post_process_prediction(prediction)\n",
    "    \n",
    "    # Calculate Dice score\n",
    "    intersection = np.sum(prediction * val_label)\n",
    "    dice_score = (2. * intersection) / (np.sum(prediction) + np.sum(val_label) + 1e-7)\n",
    "    \n",
    "    return dice_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet3D, self).__init__()\n",
    "        \n",
    "        def conv_block(in_ch, out_ch):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv3d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv3d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        def up_conv(in_ch, out_ch):\n",
    "            return nn.ConvTranspose3d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder1 = conv_block(in_channels, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "        \n",
    "        # Decoder\n",
    "        self.upconv4 = up_conv(1024, 512)\n",
    "        self.decoder4 = conv_block(1024, 512)\n",
    "        self.upconv3 = up_conv(512, 256)\n",
    "        self.decoder3 = conv_block(512, 256)\n",
    "        self.upconv2 = up_conv(256, 128)\n",
    "        self.decoder2 = conv_block(256, 128)\n",
    "        self.upconv1 = up_conv(128, 64)\n",
    "        self.decoder1 = conv_block(128, 64)\n",
    "        \n",
    "        self.output = nn.Conv3d(64, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Implementation remains the same as in your original code\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool(e1))\n",
    "        e3 = self.encoder3(self.pool(e2))\n",
    "        e4 = self.encoder4(self.pool(e3))\n",
    "        \n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "        \n",
    "        d4 = self.upconv4(b)\n",
    "        d4 = self.decoder4(torch.cat((e4, d4), dim=1))\n",
    "        d3 = self.upconv3(d4)\n",
    "        d3 = self.decoder3(torch.cat((e3, d3), dim=1))\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = self.decoder2(torch.cat((e2, d2), dim=1))\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = self.decoder1(torch.cat((e1, d1), dim=1))\n",
    "        \n",
    "        return self.output(d1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Configuration and Progress Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Use paths from PATHS dictionary\n",
    "images_path = os.path.join(PATHS['data'], 'PENGWIN_CT_train_images')\n",
    "labels_path = os.path.join(PATHS['data'], 'PENGWIN_CT_train_labels')\n",
    "\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# Dataset and DataLoader setup\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: torch.tensor(x, dtype=torch.float32)),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Initialize dataset with patch-based approach\n",
    "train_dataset = CTScanDataset(\n",
    "    images_path=images_path,\n",
    "    labels_path=labels_path,\n",
    "    patch_size=(128, 128, 128),\n",
    "    stride=(64, 64, 64)\n",
    ")\n",
    "\n",
    "# Rest of your training code remains the same\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Model initialization\n",
    "model = UNet3D(in_channels=1, out_channels=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "class TrainingMonitor:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.current_epoch = 0\n",
    "        \n",
    "    def update(self, epoch_loss):\n",
    "        self.train_losses.append(epoch_loss)\n",
    "        self.current_epoch += 1\n",
    "        \n",
    "    def plot_progress(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_losses, label='Training Loss')\n",
    "        plt.title('Training Progress')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def print_stats(self):\n",
    "        print(f\"Current epoch: {self.current_epoch}\")\n",
    "        print(f\"Best loss: {min(self.train_losses):.4f}\")\n",
    "        print(f\"Current loss: {self.train_losses[-1]:.4f}\")\n",
    "\n",
    "# Initialize training monitor\n",
    "monitor = TrainingMonitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:  92%|█████████▏| 46/50 [44:26<04:32, 68.08s/it, loss=0.318]  "
     ]
    }
   ],
   "source": [
    "# Update save paths at the start\n",
    "best_model_dice_path = os.path.join(PATHS['models'], 'best_model_dice.pth')\n",
    "best_model_loss_path = os.path.join(PATHS['models'], 'best_model_loss.pth')\n",
    "\n",
    "def train_model(model, train_loader, val_image_path, val_label_path, criterion, optimizer, num_epochs, device, monitor):\n",
    "    best_loss = float('inf')\n",
    "    best_dice = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Training loop\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        for images, masks in pbar:\n",
    "            images = images.float().to(device)\n",
    "            masks = masks.float().to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Calculate average loss for this epoch\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        monitor.update(avg_loss)\n",
    "        \n",
    "        # Validation (every 5 epochs)\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            dice_score = validate(model, val_image_path, val_label_path)\n",
    "            print(f\"Validation Dice score: {dice_score:.4f}\")\n",
    "            \n",
    "            # Save best model based on dice score\n",
    "            if dice_score > best_dice:\n",
    "                best_dice = dice_score\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'dice_score': dice_score,\n",
    "                }, best_model_dice_path)\n",
    "                print(f\"Saved new best model with Dice score: {dice_score:.4f}\")\n",
    "        \n",
    "        # Save best model based on loss\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }, best_model_loss_path)\n",
    "            print(f\"Saved new best model with loss: {best_loss:.4f}\")\n",
    "        \n",
    "        # Save regular checkpoint\n",
    "        checkpoint_path = os.path.join(CHECKPOINT_DIR, f'checkpoint_epoch_{epoch+1:03d}.pth')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'loss': avg_loss,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'dice_score': dice_score if 'dice_score' in locals() else None,\n",
    "            'best_dice': best_dice,\n",
    "            'best_loss': best_loss\n",
    "        }, checkpoint_path)\n",
    "        \n",
    "        # Plot progress every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            monitor.plot_progress()\n",
    "            monitor.print_stats()\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "all_image_files = sorted(os.listdir(images_path))\n",
    "all_label_files = sorted(os.listdir(labels_path))\n",
    "\n",
    "# Use last image for validation\n",
    "val_image_path = os.path.join(images_path, all_image_files[-1])\n",
    "val_label_path = os.path.join(labels_path, all_label_files[-1])\n",
    "\n",
    "# Function to resume training from checkpoint\n",
    "def resume_training(checkpoint_path, model, optimizer, train_loader, val_image_path, val_label_path, num_epochs, device, monitor):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    \n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "    train_model(model, train_loader, val_image_path, val_label_path,\n",
    "                criterion, optimizer, num_epochs-start_epoch, device, monitor)\n",
    "\n",
    "# Start training\n",
    "print(\"Starting training...\")\n",
    "train_model(model, train_loader, val_image_path, val_label_path, \n",
    "           criterion, optimizer, NUM_EPOCHS, device, monitor)\n",
    "\n",
    "# To resume training later, use:\n",
    "# latest_checkpoint = os.path.join(CHECKPOINT_DIR, 'checkpoint_epoch_XXX.pth')  # Replace XXX with epoch number\n",
    "# resume_training(latest_checkpoint, model, optimizer, train_loader, val_image_path, val_label_path, NUM_EPOCHS, device, monitor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingMonitor:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.val_dices = []\n",
    "        self.current_epoch = 0\n",
    "        self.plot_dir = PATHS['results']\n",
    "        \n",
    "    def plot_progress(self):\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        \n",
    "        # Plot training loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.train_losses, label='Training Loss')\n",
    "        plt.title('Training Loss Over Time')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        \n",
    "        # Plot validation dice if available\n",
    "        if self.val_dices:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(range(0, len(self.val_dices)*5, 5), self.val_dices, label='Validation Dice')\n",
    "            plt.title('Validation Dice Over Time')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Dice Score')\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        plot_path = os.path.join(self.plot_dir, f'training_progress_epoch_{self.current_epoch:03d}.png')\n",
    "        plt.savefig(plot_path)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
