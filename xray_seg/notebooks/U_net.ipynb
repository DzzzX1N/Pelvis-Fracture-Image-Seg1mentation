{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Ray Segmentation using U-Net\n",
    "\n",
    "This notebook implements pelvis X-ray segmentation using a U-Net model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.utils.pengwin_utils import (\n",
    "    load_image, \n",
    "    load_masks, \n",
    "    build_augmentation,\n",
    "    visualize_sample,\n",
    "    CATEGORIES\n",
    ")\n",
    "\n",
    "# Print versions for reproducibility\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Implementation\n",
    "First, let's create our custom dataset class for handling X-ray images and their masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', img_size=448):\n",
    "        self.root = Path(root_dir)\n",
    "        self.split = split\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        # Setup directories\n",
    "        self.input_dir = self.root / split / \"input\" / \"images\" / \"x-ray\"\n",
    "        self.output_dir = self.root / split / \"output\" / \"images\" / \"x-ray\"\n",
    "        \n",
    "        # Get file paths\n",
    "        self.image_paths = sorted(self.input_dir.glob(\"*.tif\"))\n",
    "        self.mask_paths = sorted(self.output_dir.glob(\"*.tif\"))\n",
    "        \n",
    "        assert len(self.image_paths) == len(self.mask_paths)\n",
    "        \n",
    "        # Setup augmentation\n",
    "        self.aug = build_augmentation(train=(split=='train'), img_size=img_size)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and mask\n",
    "        image = load_image(self.image_paths[idx])\n",
    "        masks, category_ids, _ = load_masks(self.mask_paths[idx])\n",
    "        \n",
    "        # Apply augmentation\n",
    "        augmented = self.aug(image=image, masks=masks)\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        image = torch.from_numpy(augmented['image']).float()\n",
    "        masks = torch.from_numpy(np.array(augmented['masks'])).float()\n",
    "        \n",
    "        return image, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Test loading one sample\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m image, masks \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMasks shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmasks\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m, in \u001b[0;36mXrayDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Load image and mask\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     image \u001b[38;5;241m=\u001b[39m load_image(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     26\u001b[0m     masks, category_ids, _ \u001b[38;5;241m=\u001b[39m load_masks(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmask_paths[idx])\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# Apply augmentation\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Initialize dataset\n",
    "dataset = XrayDataset('path/to/your/data', 'train')\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Test loading one sample\n",
    "image, masks = dataset[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Masks shape: {masks.shape}\")\n",
    "\n",
    "# Visualize sample\n",
    "vis_img = visualize_sample(\n",
    "    image.numpy(), \n",
    "    masks.numpy(), \n",
    "    category_ids=list(CATEGORIES.values()),\n",
    "    fragment_ids=[1]*len(CATEGORIES)\n",
    ")\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(vis_img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. U-Net Model Implementation\n",
    "Now let's implement our U-Net architecture for segmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pelvis_seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
